{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN-Training.ipynb","version":"0.3.2","provenance":[{"file_id":"1Wx2ea3RoSRCadfVEHd_WiYBwxk4BaDUj","timestamp":1559203665033}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"aWowSqstg_FL","colab_type":"text"},"source":["# Convolutional Neural Network Model (10-Fold-Cross-Validation)"]},{"cell_type":"markdown","metadata":{"id":"5Eauy2DfhqPA","colab_type":"text"},"source":["This file contains 10-fold-cross-validation and parameter tuning in order to demonstrate the process of tunning the model.   \n","**For the final version of model and its accuracy and running time please see CNN-Trained.ipynb**"]},{"cell_type":"markdown","metadata":{"id":"21la5bNhhUEC","colab_type":"text"},"source":["## Import Pakages"]},{"cell_type":"code","metadata":{"id":"Xmyqt777zJvZ","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","from keras.models import Sequential\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dropout\n","from keras.layers.core import Dense\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from imutils import build_montages\n","from keras import backend as K\n","from keras.utils import np_utils\n","from keras.datasets import fashion_mnist\n","from keras.optimizers import SGD, Adadelta\n","from sklearn.metrics import classification_report\n","import matplotlib\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import confusion_matrix, classification_report\n","from keras.wrappers.scikit_learn import KerasClassifier\n","import time\n","from keras.utils import plot_model\n","from keras.models import load_model\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import KFold, cross_val_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OdQqzEASz17X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":955},"outputId":"1d3617e2-d8d0-4fde-a638-cc4e1c19134f","executionInfo":{"status":"ok","timestamp":1559221269680,"user_tz":-600,"elapsed":4128,"user":{"displayName":"Rene Guo","photoUrl":"https://lh6.googleusercontent.com/-LjTOT_aVzCU/AAAAAAAAAAI/AAAAAAAAADo/IXNtRrRDoG4/s64/photo.jpg","userId":"06912656137012815004"}}},"source":["!cat /proc/cpuinfo\n","\n","\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2300.000\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf\n","bogomips\t: 4600.00\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RKeX0TfZhkYd","colab_type":"text"},"source":["## Load and Process Data"]},{"cell_type":"code","metadata":{"id":"jBk_MW3rhiFi","colab_type":"code","colab":{}},"source":["# load data\n","((x_train, y_train), (x_test, y_test)) = fashion_mnist.load_data()\n","# rashape data\n","x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n","x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZANhxF41RP9","colab_type":"code","colab":{}},"source":["# scale data to the range of [0, 1]\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test = x_test.astype(\"float32\") / 255.0\n","\n","y_train = np_utils.to_categorical(y_train, 10)\n","y_test = np_utils.to_categorical(y_test, 10)\n","\n","# initialize the label names\n","labelNames = [\"t-Shirt\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bDVru580hZk3","colab_type":"text"},"source":["## Specify Prameters"]},{"cell_type":"code","metadata":{"id":"ReVgc1U1iq-1","colab_type":"code","colab":{}},"source":["# number of epoches\n","NUM_EPOCHS = 30\n","# learning rate\n","LEARN_RATE = 0.1\n","# batch size\n","BATCH_SIZE = 200\n","\n","# initialize the optimizer and model\n","adadelta=Adadelta()\n","sgd = SGD(lr=LEARN_RATE, momentum=0.9, decay=LEARN_RATE / NUM_EPOCHS)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jM3xnHqgi3w4","colab_type":"text"},"source":["## Construct Model"]},{"cell_type":"code","metadata":{"id":"PYtKqKLEAuSL","colab_type":"code","colab":{}},"source":["class CNN:\n","  def build(width=28, height=28, depth=1, optimizer=adadelta, dropout_rate = 0.25, BN = False):\n","    chanDim = -1\n","    input_shape = (height, width, depth)\n","    model = Sequential()\n","    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n","    if (BN is True):\n","      model.add(BatchNormalization(axis=chanDim))\n","    model.add(Conv2D(64, (3, 3), activation='relu'))\n","    if (BN is True):\n","      model.add(BatchNormalization(axis=chanDim))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(dropout_rate))\n","    model.add(Dense(10, activation='softmax'))\n","    \n","    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c5nmfU3HjeuL","colab_type":"text"},"source":["## Compile Model"]},{"cell_type":"code","metadata":{"id":"8Jlgh4R1_nk3","colab_type":"code","colab":{}},"source":["# model = CNN.build(optimizer = adadelta, dropout_rate = 0, BN = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFN1FP5G_XAi","colab_type":"code","colab":{}},"source":["# model = CNN.build(optimizer = adadelta, dropout_rate = 0.25, BN = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtTeHCDZo5gS","colab_type":"code","colab":{}},"source":["# final model used\n","model = CNN.build(optimizer = adadelta, dropout_rate = 0.6, BN = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g-YQXC1rsEEE","colab_type":"code","colab":{}},"source":["# model = CNN.build(optimizer = adadelta, dropout_rate = 0.6, BN = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KEo_ANcGAIOY","colab_type":"code","colab":{}},"source":["# model = CNN.build(optimizer = sgd, dropout_rate = 0.6, BN = False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F-WCnpFnANDO","colab_type":"code","colab":{}},"source":["# model = CNN.build(optimizer = adadelta, dropout_rate = 0.25, BN = True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1X5eZKwWkF4d","colab_type":"text"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"id":"jO5ybArcAPjI","colab_type":"code","outputId":"38bb3174-2ca7-4a57-e18a-98fa17f5410e","executionInfo":{"status":"ok","timestamp":1559213169305,"user_tz":-600,"elapsed":1113860,"user":{"displayName":"Rene Guo","photoUrl":"https://lh6.googleusercontent.com/-LjTOT_aVzCU/AAAAAAAAAAI/AAAAAAAAADo/IXNtRrRDoG4/s64/photo.jpg","userId":"06912656137012815004"}},"colab":{"base_uri":"https://localhost:8080/","height":10404}},"source":["# define 10-fold cross validation test harness\n","seed = 7\n","\n","kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","\n","cvscores = []\n","\n","start = time.time()\n","\n","for i, (train_index, val_index) in enumerate(kf.split(x_train, y_train.argmax(1))):\n","  x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n","  y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n","  \n","  model = CNN.build(optimizer = adadelta, dropout_rate = 0.6, BN = False)\n","  model.fit(x_train_kf, y_train_kf, epochs=30, batch_size=200, verbose=1)\n","\n","  scores = model.evaluate(x_val_kf, y_val_kf, verbose=0)\n","  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n","  cvscores.append(scores[1] * 100)\n","print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n","\n","end = time.time()\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","54000/54000 [==============================] - 4s 76us/step - loss: 0.7040 - acc: 0.7496\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.4474 - acc: 0.8405\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3990 - acc: 0.8577\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.3652 - acc: 0.8711\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3446 - acc: 0.8783\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.3246 - acc: 0.8852\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3089 - acc: 0.8903\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2953 - acc: 0.8951\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2867 - acc: 0.8981\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2749 - acc: 0.9026\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2671 - acc: 0.9053\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2583 - acc: 0.9078\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2547 - acc: 0.9099\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2522 - acc: 0.9094\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2452 - acc: 0.9123\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2388 - acc: 0.9151\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2370 - acc: 0.9146\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2298 - acc: 0.9183\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2263 - acc: 0.9202\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2235 - acc: 0.9200\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2213 - acc: 0.9210\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2181 - acc: 0.9224\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2116 - acc: 0.9221\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2117 - acc: 0.9240\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2087 - acc: 0.9239\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.2073 - acc: 0.9262\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2069 - acc: 0.9276\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2052 - acc: 0.9267\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1992 - acc: 0.9296\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.1975 - acc: 0.9287\n","acc: 93.18%\n","Epoch 1/30\n","54000/54000 [==============================] - 4s 77us/step - loss: 0.6908 - acc: 0.7554\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.4419 - acc: 0.8439\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.3845 - acc: 0.8631\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3568 - acc: 0.8749\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3330 - acc: 0.8811\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3114 - acc: 0.8904\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2985 - acc: 0.8946\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2881 - acc: 0.8969\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2765 - acc: 0.9008\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2680 - acc: 0.9055\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2591 - acc: 0.9075\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2533 - acc: 0.9098\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2506 - acc: 0.9103\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2409 - acc: 0.9134\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2372 - acc: 0.9165\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2342 - acc: 0.9163\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2300 - acc: 0.9175\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2270 - acc: 0.9201\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2215 - acc: 0.9207\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 70us/step - loss: 0.2194 - acc: 0.9208\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2133 - acc: 0.9232\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2100 - acc: 0.9245\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2130 - acc: 0.9234\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2084 - acc: 0.9259\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2062 - acc: 0.9265\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2018 - acc: 0.9290\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2021 - acc: 0.9283\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1979 - acc: 0.9301\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.1947 - acc: 0.9294\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1939 - acc: 0.9299\n","acc: 92.93%\n","Epoch 1/30\n","54000/54000 [==============================] - 4s 79us/step - loss: 0.6993 - acc: 0.7538\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.4479 - acc: 0.8422\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3940 - acc: 0.8610\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.3643 - acc: 0.8715\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.3398 - acc: 0.8798\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.3184 - acc: 0.8880\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3062 - acc: 0.8920\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2932 - acc: 0.8944\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2846 - acc: 0.8975\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2717 - acc: 0.9040\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2659 - acc: 0.9038\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2613 - acc: 0.9070\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2512 - acc: 0.9095\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2507 - acc: 0.9104\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2427 - acc: 0.9126\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2376 - acc: 0.9155\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2343 - acc: 0.9170\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2300 - acc: 0.9182\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2250 - acc: 0.9197\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2244 - acc: 0.9193\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2188 - acc: 0.9216\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2177 - acc: 0.9231\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2126 - acc: 0.9228\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2121 - acc: 0.9234\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2066 - acc: 0.9266\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2057 - acc: 0.9260\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2053 - acc: 0.9266\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2022 - acc: 0.9264\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1975 - acc: 0.9292\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1994 - acc: 0.9285\n","acc: 93.55%\n","Epoch 1/30\n","54000/54000 [==============================] - 4s 80us/step - loss: 0.7104 - acc: 0.7488\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.4571 - acc: 0.8393\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3990 - acc: 0.8606\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3623 - acc: 0.8694\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3406 - acc: 0.8784\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3196 - acc: 0.8858\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3057 - acc: 0.8903\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2939 - acc: 0.8941\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.2792 - acc: 0.8996\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2737 - acc: 0.9021\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2667 - acc: 0.9050\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2602 - acc: 0.9072\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2517 - acc: 0.9108\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2467 - acc: 0.9117\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2436 - acc: 0.9126\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2388 - acc: 0.9134\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2335 - acc: 0.9164\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2317 - acc: 0.9171\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2257 - acc: 0.9194\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2210 - acc: 0.9223\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2160 - acc: 0.9231\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2161 - acc: 0.9228\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2117 - acc: 0.9235\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2111 - acc: 0.9252\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2039 - acc: 0.9271\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2018 - acc: 0.9276\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2002 - acc: 0.9293\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1971 - acc: 0.9298\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1941 - acc: 0.9310\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1957 - acc: 0.9317\n","acc: 93.42%\n","Epoch 1/30\n","54000/54000 [==============================] - 4s 82us/step - loss: 0.7182 - acc: 0.7451\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.4519 - acc: 0.8413\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3961 - acc: 0.8613\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.3627 - acc: 0.8714\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3361 - acc: 0.8806\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3239 - acc: 0.8845\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3062 - acc: 0.8917\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2934 - acc: 0.8957\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2861 - acc: 0.8982\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2725 - acc: 0.9030\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2683 - acc: 0.9047\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2610 - acc: 0.9064\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 70us/step - loss: 0.2555 - acc: 0.9082\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 70us/step - loss: 0.2496 - acc: 0.9105\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2443 - acc: 0.9131\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2385 - acc: 0.9144\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2337 - acc: 0.9173\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2314 - acc: 0.9164\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2266 - acc: 0.9184\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2253 - acc: 0.9194\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2209 - acc: 0.9206\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2168 - acc: 0.9221\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2134 - acc: 0.9235\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2087 - acc: 0.9260\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2086 - acc: 0.9256\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2028 - acc: 0.9286\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2052 - acc: 0.9267\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2010 - acc: 0.9281\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2015 - acc: 0.9286\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1944 - acc: 0.9308\n","acc: 92.48%\n","Epoch 1/30\n","54000/54000 [==============================] - 5s 86us/step - loss: 0.7022 - acc: 0.7501\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.4555 - acc: 0.8376\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.4005 - acc: 0.8581\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3668 - acc: 0.8716\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.3386 - acc: 0.8807\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3215 - acc: 0.8858\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3067 - acc: 0.8908\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2936 - acc: 0.8949\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2816 - acc: 0.9004\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2740 - acc: 0.9036\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2662 - acc: 0.9051\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2592 - acc: 0.9073\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2513 - acc: 0.9106\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.2451 - acc: 0.9129\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2442 - acc: 0.9121\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2372 - acc: 0.9160\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2304 - acc: 0.9182\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2288 - acc: 0.9187\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2266 - acc: 0.9206\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2196 - acc: 0.9202\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2185 - acc: 0.9215\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.2135 - acc: 0.9247\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2131 - acc: 0.9244\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2088 - acc: 0.9258\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2075 - acc: 0.9253\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2060 - acc: 0.9268\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2025 - acc: 0.9289\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1992 - acc: 0.9284\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1988 - acc: 0.9294\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.1965 - acc: 0.9302\n","acc: 92.85%\n","Epoch 1/30\n","54000/54000 [==============================] - 5s 85us/step - loss: 0.7203 - acc: 0.7423\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.4591 - acc: 0.8349\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.4006 - acc: 0.8574\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.3711 - acc: 0.8667\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3466 - acc: 0.8770\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3215 - acc: 0.8859\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3111 - acc: 0.8884\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2956 - acc: 0.8945\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2834 - acc: 0.8986\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2760 - acc: 0.9017\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2675 - acc: 0.9046\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2630 - acc: 0.9065\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2542 - acc: 0.9088\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2497 - acc: 0.9100\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2420 - acc: 0.9139\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2336 - acc: 0.9167\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2353 - acc: 0.9162\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2289 - acc: 0.9177\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2263 - acc: 0.9186\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2217 - acc: 0.9204\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2191 - acc: 0.9215\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2151 - acc: 0.9228\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2098 - acc: 0.9249\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2094 - acc: 0.9243\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2072 - acc: 0.9250\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2041 - acc: 0.9271\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2021 - acc: 0.9273\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1979 - acc: 0.9292\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1984 - acc: 0.9286\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1969 - acc: 0.9288\n","acc: 93.45%\n","Epoch 1/30\n","54000/54000 [==============================] - 5s 87us/step - loss: 0.6876 - acc: 0.7543\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.4458 - acc: 0.8419\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3907 - acc: 0.8602\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3575 - acc: 0.8715\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3348 - acc: 0.8803\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.3134 - acc: 0.8866\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 70us/step - loss: 0.3005 - acc: 0.8927\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 70us/step - loss: 0.2872 - acc: 0.8978\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2797 - acc: 0.8990\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2722 - acc: 0.9026\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2622 - acc: 0.9054\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2556 - acc: 0.9080\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2519 - acc: 0.9105\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2480 - acc: 0.9114\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2398 - acc: 0.9138\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2380 - acc: 0.9145\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2306 - acc: 0.9183\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2281 - acc: 0.9185\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2222 - acc: 0.9195\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2189 - acc: 0.9215\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2183 - acc: 0.9227\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2163 - acc: 0.9225\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2133 - acc: 0.9241\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2088 - acc: 0.9247\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2073 - acc: 0.9251\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2014 - acc: 0.9274\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1997 - acc: 0.9280\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2001 - acc: 0.9284\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.1985 - acc: 0.9287\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.1939 - acc: 0.9294\n","acc: 92.92%\n","Epoch 1/30\n","54000/54000 [==============================] - 5s 88us/step - loss: 0.6958 - acc: 0.7517\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.4557 - acc: 0.8375\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.3979 - acc: 0.8586\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3640 - acc: 0.8717\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3355 - acc: 0.8807\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3201 - acc: 0.8848\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.3064 - acc: 0.8911\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2909 - acc: 0.8959\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2787 - acc: 0.8996\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2714 - acc: 0.9036\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2641 - acc: 0.9060\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2579 - acc: 0.9071\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2538 - acc: 0.9092\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2465 - acc: 0.9099\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2403 - acc: 0.9142\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2345 - acc: 0.9166\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2320 - acc: 0.9185\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2260 - acc: 0.9176\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2238 - acc: 0.9193\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2193 - acc: 0.9226\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2180 - acc: 0.9220\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2154 - acc: 0.9224\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2118 - acc: 0.9236\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2100 - acc: 0.9246\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2070 - acc: 0.9261\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2036 - acc: 0.9277\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2017 - acc: 0.9280\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1989 - acc: 0.9274\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 66us/step - loss: 0.2004 - acc: 0.9286\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1976 - acc: 0.9306\n","acc: 92.13%\n","Epoch 1/30\n","54000/54000 [==============================] - 5s 89us/step - loss: 0.6829 - acc: 0.7585\n","Epoch 2/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.4453 - acc: 0.8424\n","Epoch 3/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3908 - acc: 0.8609\n","Epoch 4/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3570 - acc: 0.8732\n","Epoch 5/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3340 - acc: 0.8801\n","Epoch 6/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3176 - acc: 0.8866\n","Epoch 7/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.3026 - acc: 0.8909\n","Epoch 8/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2893 - acc: 0.8961\n","Epoch 9/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2775 - acc: 0.8990\n","Epoch 10/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2692 - acc: 0.9041\n","Epoch 11/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2615 - acc: 0.9076\n","Epoch 12/30\n","54000/54000 [==============================] - 4s 69us/step - loss: 0.2551 - acc: 0.9082\n","Epoch 13/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.2472 - acc: 0.9115\n","Epoch 14/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2425 - acc: 0.9130\n","Epoch 15/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2403 - acc: 0.9144\n","Epoch 16/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2332 - acc: 0.9173\n","Epoch 17/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2312 - acc: 0.9178\n","Epoch 18/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2245 - acc: 0.9193\n","Epoch 19/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2235 - acc: 0.9196\n","Epoch 20/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2161 - acc: 0.9232\n","Epoch 21/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2154 - acc: 0.9229\n","Epoch 22/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2116 - acc: 0.9239\n","Epoch 23/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2137 - acc: 0.9237\n","Epoch 24/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2076 - acc: 0.9255\n","Epoch 25/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2026 - acc: 0.9270\n","Epoch 26/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.2020 - acc: 0.9272\n","Epoch 27/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1991 - acc: 0.9296\n","Epoch 28/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1959 - acc: 0.9305\n","Epoch 29/30\n","54000/54000 [==============================] - 4s 67us/step - loss: 0.1984 - acc: 0.9299\n","Epoch 30/30\n","54000/54000 [==============================] - 4s 68us/step - loss: 0.1932 - acc: 0.9302\n","acc: 92.92%\n","92.98% (+/- 0.42%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TdiZp1cNjxuR","colab_type":"text"},"source":["## Genrate Result"]},{"cell_type":"code","metadata":{"id":"noaKqTg_2Ke4","colab_type":"code","colab":{}},"source":["# plot model structure\n","plot_model(model, to_file='model.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLApuDmxytiW","colab_type":"code","outputId":"1734d5c6-4f62-42ee-d0b4-a8c743f207cc","executionInfo":{"status":"ok","timestamp":1559200710841,"user_tz":-600,"elapsed":2046,"user":{"displayName":"Rene Guo","photoUrl":"https://lh6.googleusercontent.com/-LjTOT_aVzCU/AAAAAAAAAAI/AAAAAAAAADo/IXNtRrRDoG4/s64/photo.jpg","userId":"06912656137012815004"}},"colab":{"base_uri":"https://localhost:8080/","height":360}},"source":["# make predictions on the test set\n","preds = model.predict(x_test)\n","\n","# show a nicely formatted classification report\n","print(classification_report(y_test.argmax(axis=1), preds.argmax(axis=1),\n","                            target_names=labelNames))\n","\n","N = NUM_EPOCHS\n","plt.style.use(\"ggplot\")\n","plt.figure()\n","plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n","plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n","plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n","plt.title(\"Training Loss and Accuracy with Batch Normalization\")\n","plt.xlabel(\"Epoch #\")\n","plt.ylabel(\"Loss/Accuracy\")\n","plt.legend(loc=\"lower left\")\n","plt.savefig(\"plot.png\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     t-Shirt       0.86      0.91      0.89      1000\n","     trouser       0.99      0.98      0.99      1000\n","    pullover       0.85      0.91      0.88      1000\n","       dress       0.92      0.94      0.93      1000\n","        coat       0.90      0.87      0.88      1000\n","      sandal       0.99      0.98      0.99      1000\n","       shirt       0.82      0.73      0.77      1000\n","     sneaker       0.96      0.99      0.97      1000\n","         bag       0.99      0.98      0.99      1000\n","  ankle boot       0.98      0.97      0.98      1000\n","\n","    accuracy                           0.93     10000\n","   macro avg       0.93      0.93      0.93     10000\n","weighted avg       0.93      0.93      0.93     10000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py:514: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n","  max_open_warning, RuntimeWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"e2OjdP9g7Iy1","colab_type":"code","colab":{}},"source":["# save the model\n","model.save('CNN.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9if2buZC7Oh6","colab_type":"code","colab":{}},"source":["# returns a compiled model\n","# identical to the previous one\n","model = load_model('CNN.h5')"],"execution_count":0,"outputs":[]}]}